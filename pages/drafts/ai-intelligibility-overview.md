---
layout: post
title: 'Project #1: AI Intelligibility With a Side Order of Auto ML'
---

Although I've been mucking around with machine learning and AI for years, I've never felt comfortable using it.  What I've realized is that it's not just me -- as a terrific study by Jennifer ____ and crew showed, there are a lot of data scientists who don't entirely grok what they're doing. 

At the same time, it's become increasingly clear that while treating AI/ML as a black box is fine for tagging pictures as cats vs dogs or recommending which movie you might like, it can hurt or kill people once you step outside these low risk endeavors.  Quantitative data can be extremely powerful, but it's also brittle.  If you have no clue what's inside the black box, you'll end up with HR systems that discriminate against women and recommendations on treating pnemonia that treat asthma as a sign that doctors don't need to be too worried.  

There's a field that's just beginning to come into its own that worries about issues like this.  It's called machine learning inteligbility or explainable AI (XAI).  And I think it's a great candidate for exploring the Makers All strategy of [Smoothing the Learning Curve](https://toolkit.makersall.org/pages/30-smooth/00-index.html).

I'm particularly interested in AI intelligibility because of another trend:  Auto ML.  